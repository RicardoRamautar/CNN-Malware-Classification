import torchvision.transforms as transforms
from torchvision.transforms import InterpolationMode

PARAM_GRID = {
    'nr_conv_layers' : [2,3,4],
    'nr_ff_layers'   : [1, 2],
    'out_channels'   : [[40, 50], [70, 90], 
                        [25, 50, 50], [50, 70, 70], [70, 90, 90],
                        [20, 30, 40, 50], [50, 70, 70, 90]],
    'ff_output_sizes': [[25], [50, 25]],
    'kernel_sizes'   : [[5, 3], [9, 5], 
                        [5, 3, 3], [9, 5, 5],
                        [5, 3, 3, 3], [9, 5, 5, 3]]
}

# Base model - MalImg
base_model_malimg =  {"nr_conv_layers": 3,
                "nr_ff_layers": 1,
                "out_channels": [50, 70, 70],
                "ff_output_sizes": [25],
                "kernel_size": [5, 3, 3]}

# Best model - MalImg
best_model_malimg =  {"nr_conv_layers": 3,
                "nr_ff_layers": 1,
                "out_channels": [50, 70, 70],
                "ff_output_sizes": [25],
                "kernel_size": [5, 3, 3]}

# Best model - Akash Dataset
best_model_dataAkash =  {"nr_conv_layers": 3,
                "nr_ff_layers": 1,
                "out_channels": [50, 70, 70],
                "ff_output_sizes": [538],
                "kernel_size": [5, 3, 3]}

AKASH_DATASET_TRANSFORM = transforms.Compose([
    transforms.Resize((256, 256)), 
    transforms.ToTensor()
])

MALIMG_DATASET_TRANSFORM = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((256, 256), interpolation=InterpolationMode.LANCZOS),
    transforms.ToTensor()
])