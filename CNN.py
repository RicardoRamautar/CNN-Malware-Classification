import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split, Subset
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, mean_absolute_error, accuracy_score
import seaborn as sns
import time
from torch.cuda.amp import GradScaler, autocast
import pandas as pd
from torchvision.transforms import InterpolationMode
from pathlib import Path
import os
from torch.optim.lr_scheduler import ReduceLROnPlateau

class CNN(nn.Module):
    def __init__(self, nr_conv_layers, nr_ff_layers, out_channels, ff_output_sizes, kernel_sizes, init_channel=1):
        super(CNN, self).__init__()
        
        # Storage for convolutional and feedforward layers
        self.conv_layers = nn.ModuleList()
        self.fnn_layers = nn.ModuleList()
        
        # Dimension of input images (256x256)
        conv_output_size = 256
                
        # Create and store convolutional layers
        for i in range(nr_conv_layers):
            conv_output = out_channels[i]
            conv_size   = kernel_sizes[i]
            if i == 0: 
                nr_conv_input = init_channel
            else: 
                nr_conv_input = out_channels[i-1]
                
            conv_layer = nn.Conv2d(nr_conv_input, conv_output, conv_size)
            self.conv_layers.append(conv_layer)
            
            # Calculate size of output
            conv_output_size = conv_output_size - (conv_size // 2)*2
            conv_output_size = conv_output_size / 2

        conv_output_size = int(conv_output_size)
        
        # Local Response Normalization
        self.norm = nn.LocalResponseNorm(size=4, alpha=0.001 / 9.0, beta=0.75, k=1.0)

        # Max pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        
        # Store and create feedforward layers
        for i in range(nr_ff_layers):
            if i == 0:
                input_features = out_channels[-1] * conv_output_size**2
            else:
                input_features = ff_output_sizes[i-1]
            fnn_layer = nn.Linear(input_features, ff_output_sizes[i])
            self.fnn_layers.append(fnn_layer)

    def forward(self, x, apply_softmax = False):
        """Forward step"""

        # Pass through convolutional layers
        for conv_layer in self.conv_layers:
            x = self.norm(self.pool(F.relu(conv_layer(x))))
        
        # Flatten the output for the fully connected layers
        x = x.view(x.size(0), -1)
        
        # Pass through feedforward layers
        for i, fnn_layer in enumerate(self.fnn_layers):
            if i < len(self.fnn_layers) - 1:
                x = F.relu(fnn_layer(x))
            else:
                x = fnn_layer(x)
                
        # Apply Softmax at evaluation
        if apply_softmax:
            x = F.softmax(x, dim=1)
        return x
    
    def reset_weights(self):
        """Reset model weights"""

        for layer in self.modules():
            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.constant_(layer.bias, 0)